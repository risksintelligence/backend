#!/usr/bin/env python3
"""
End-to-End Integration Tests
Tests complete data ingestion pipeline, Monte Carlo simulation, and backtesting
"""

import asyncio
import json
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

import httpx
import structlog

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

logger = structlog.get_logger()

class E2ETestRunner:
    """End-to-end test runner for RiskX Observatory"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.test_results = {
            "start_time": datetime.now().isoformat(),
            "tests": [],
            "summary": {
                "total_tests": 0,
                "passed": 0,
                "failed": 0,
                "skipped": 0
            }
        }
        
    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all end-to-end tests"""
        logger.info("üöÄ Starting End-to-End Integration Tests")
        
        tests = [
            ("Health Check", self.test_health_check),
            ("Data Ingestion", self.test_data_ingestion),
            ("GERI Computation", self.test_geri_computation),
            ("Monte Carlo Forecast", self.test_monte_carlo_forecast),
            ("Regime Detection", self.test_regime_detection),
            ("Anomaly Detection", self.test_anomaly_detection),
            ("Risk Assessment", self.test_risk_assessment),
            ("Governance Pipeline", self.test_governance_pipeline),
            ("Explainability Audit", self.test_explainability_audit),
            ("Performance Metrics", self.test_performance_metrics)
        ]
        
        for test_name, test_func in tests:
            result = await self.run_test(test_name, test_func)
            self.test_results["tests"].append(result)
            
            if result["status"] == "pass":
                self.test_results["summary"]["passed"] += 1
            elif result["status"] == "fail":
                self.test_results["summary"]["failed"] += 1
            else:
                self.test_results["summary"]["skipped"] += 1
                
        self.test_results["summary"]["total_tests"] = len(tests)
        self.test_results["end_time"] = datetime.now().isoformat()
        
        return self.test_results
    
    async def run_test(self, test_name: str, test_func) -> Dict[str, Any]:
        """Run a single test with timing and error handling"""
        logger.info(f"Running test: {test_name}")
        
        start_time = time.time()
        result = {
            "name": test_name,
            "status": "unknown",
            "duration_ms": 0,
            "message": "",
            "data": None,
            "errors": []
        }
        
        try:
            test_result = await test_func()
            result.update(test_result)
            result["duration_ms"] = (time.time() - start_time) * 1000
            
        except Exception as e:
            result["status"] = "fail"
            result["duration_ms"] = (time.time() - start_time) * 1000
            result["errors"] = [str(e)]
            result["message"] = f"Test failed with exception: {str(e)}"
            
        return result
    
    async def test_health_check(self) -> Dict[str, Any]:
        """Test basic health check endpoint"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/health")
            
            if response.status_code == 200:
                return {
                    "status": "pass",
                    "message": "Health check successful",
                    "data": response.json()
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Health check failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_data_ingestion(self) -> Dict[str, Any]:
        """Test data ingestion and historical data availability"""
        async with httpx.AsyncClient() as client:
            # Test analytics history endpoint
            response = await client.get(f"{self.base_url}/api/v1/analytics/history?days=30")
            
            if response.status_code == 200:
                data = response.json()
                history_count = len(data.get("history", []))
                
                return {
                    "status": "pass" if history_count > 0 else "fail",
                    "message": f"Found {history_count} historical data points",
                    "data": {"history_count": history_count, "sample": data.get("history", [])[:3]}
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Data ingestion test failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_geri_computation(self) -> Dict[str, Any]:
        """Test GERI computation with comprehensive metrics"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/api/v1/analytics/geri")
            
            if response.status_code == 200:
                data = response.json()
                score = data.get("score", 0)
                confidence = data.get("confidence", 0)
                
                # Validate score range and structure
                valid_score = 0 <= score <= 100
                has_risk_taxonomy = "risk_taxonomy" in data
                has_drivers = "drivers" in data and len(data["drivers"]) > 0
                
                if valid_score and has_risk_taxonomy and has_drivers:
                    return {
                        "status": "pass",
                        "message": f"GERI score: {score:.2f}, confidence: {confidence}%",
                        "data": {
                            "score": score,
                            "confidence": confidence,
                            "band": data.get("band"),
                            "drivers_count": len(data.get("drivers", []))
                        }
                    }
                else:
                    return {
                        "status": "fail",
                        "message": "GERI computation validation failed",
                        "errors": [f"Valid score: {valid_score}, Has taxonomy: {has_risk_taxonomy}, Has drivers: {has_drivers}"]
                    }
            else:
                return {
                    "status": "fail",
                    "message": f"GERI computation failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_monte_carlo_forecast(self) -> Dict[str, Any]:
        """Test Monte Carlo forecasting capabilities"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/api/v1/ai/forecast/next-24h")
            
            if response.status_code == 200:
                data = response.json()
                delta = data.get("delta", 0)
                p_gt_5 = data.get("p_gt_5", 0)
                confidence_interval = data.get("confidence_interval", [])
                
                # Validate forecast structure
                valid_probability = 0 <= p_gt_5 <= 1
                has_confidence_interval = len(confidence_interval) == 2
                has_drivers = "drivers" in data
                
                if valid_probability and has_confidence_interval and has_drivers:
                    return {
                        "status": "pass",
                        "message": f"Forecast delta: {delta:.3f}, P(>5%): {p_gt_5:.3f}",
                        "data": {
                            "delta": delta,
                            "p_gt_5": p_gt_5,
                            "confidence_interval": confidence_interval,
                            "drivers_count": len(data.get("drivers", []))
                        }
                    }
                else:
                    return {
                        "status": "fail",
                        "message": "Monte Carlo forecast validation failed",
                        "errors": [f"Valid prob: {valid_probability}, Has CI: {has_confidence_interval}, Has drivers: {has_drivers}"]
                    }
            else:
                return {
                    "status": "fail",
                    "message": f"Monte Carlo forecast failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_regime_detection(self) -> Dict[str, Any]:
        """Test regime detection and classification"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/api/v1/ai/regime/current")
            
            if response.status_code == 200:
                data = response.json()
                regime = data.get("regime", "")
                probabilities = data.get("probabilities", {})
                confidence = data.get("confidence", 0)
                
                # Validate regime detection
                has_regime = len(regime) > 0
                has_probabilities = len(probabilities) > 0
                valid_confidence = 0 <= confidence <= 1
                
                if has_regime and has_probabilities and valid_confidence:
                    return {
                        "status": "pass",
                        "message": f"Current regime: {regime} (confidence: {confidence:.2f})",
                        "data": {
                            "regime": regime,
                            "confidence": confidence,
                            "regime_count": len(probabilities)
                        }
                    }
                else:
                    return {
                        "status": "fail",
                        "message": "Regime detection validation failed",
                        "errors": [f"Has regime: {has_regime}, Has probs: {has_probabilities}, Valid conf: {valid_confidence}"]
                    }
            else:
                return {
                    "status": "fail",
                    "message": f"Regime detection failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_anomaly_detection(self) -> Dict[str, Any]:
        """Test anomaly detection pipeline"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/api/v1/anomalies/history?days=30")
            
            if response.status_code == 200:
                data = response.json()
                anomalies = data.get("anomalies", [])
                
                return {
                    "status": "pass",
                    "message": f"Found {len(anomalies)} anomalies in last 30 days",
                    "data": {
                        "anomaly_count": len(anomalies),
                        "sample_anomalies": anomalies[:3] if anomalies else []
                    }
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Anomaly detection failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_risk_assessment(self) -> Dict[str, Any]:
        """Test risk assessment and RAS calculation"""
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.base_url}/api/v1/impact/ras")
            
            if response.status_code == 200:
                data = response.json()
                ras_score = data.get("ras_score", 0)
                
                return {
                    "status": "pass",
                    "message": f"RAS score computed: {ras_score:.2f}",
                    "data": {"ras_score": ras_score, "full_response": data}
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Risk assessment failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_governance_pipeline(self) -> Dict[str, Any]:
        """Test AI governance and model registry"""
        async with httpx.AsyncClient() as client:
            # Test governance models endpoint
            response = await client.get(f"{self.base_url}/api/v1/ai/governance/models")
            
            if response.status_code in [200, 500]:  # 500 expected if no models registered
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])
                    message = f"Governance pipeline operational with {len(models)} models"
                else:
                    message = "Governance pipeline operational (no models registered)"
                
                return {
                    "status": "pass",
                    "message": message,
                    "data": {"status_code": response.status_code}
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Governance pipeline failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_explainability_audit(self) -> Dict[str, Any]:
        """Test explainability and audit logging"""
        async with httpx.AsyncClient() as client:
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
            
            response = await client.get(
                f"{self.base_url}/api/v1/ai/explainability/audit-log?start_date={start_date}&end_date={end_date}"
            )
            
            if response.status_code == 200:
                data = response.json()
                total_entries = data.get("total_entries", 0)
                
                return {
                    "status": "pass",
                    "message": f"Explainability audit operational ({total_entries} entries)",
                    "data": {"total_entries": total_entries}
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Explainability audit failed: HTTP {response.status_code}",
                    "errors": [response.text]
                }
    
    async def test_performance_metrics(self) -> Dict[str, Any]:
        """Test performance monitoring and metrics collection"""
        async with httpx.AsyncClient() as client:
            # Test multiple endpoints to validate performance
            endpoints_to_test = [
                "/api/v1/analytics/geri",
                "/api/v1/ai/forecast/next-24h",
                "/api/v1/ai/regime/current"
            ]
            
            performance_data = []
            for endpoint in endpoints_to_test:
                start_time = time.time()
                response = await client.get(f"{self.base_url}{endpoint}")
                response_time = (time.time() - start_time) * 1000
                
                performance_data.append({
                    "endpoint": endpoint,
                    "response_time_ms": response_time,
                    "status_code": response.status_code
                })
            
            avg_response_time = sum(p["response_time_ms"] for p in performance_data) / len(performance_data)
            all_successful = all(p["status_code"] == 200 for p in performance_data)
            
            if all_successful and avg_response_time < 5000:  # 5 second threshold
                return {
                    "status": "pass",
                    "message": f"Performance acceptable (avg: {avg_response_time:.1f}ms)",
                    "data": {"performance_data": performance_data, "avg_response_time": avg_response_time}
                }
            else:
                return {
                    "status": "fail",
                    "message": f"Performance issues detected (avg: {avg_response_time:.1f}ms)",
                    "errors": [f"All successful: {all_successful}", f"Response time threshold exceeded"]
                }

def print_test_results(results: Dict[str, Any]):
    """Print formatted test results"""
    print("\n" + "="*80)
    print("üß™ END-TO-END INTEGRATION TEST RESULTS")
    print("="*80)
    
    summary = results["summary"]
    print(f"\nüìä SUMMARY:")
    print(f"   Total Tests: {summary['total_tests']}")
    print(f"   ‚úÖ Passed: {summary['passed']}")
    print(f"   ‚ùå Failed: {summary['failed']}")
    print(f"   ‚è≠Ô∏è  Skipped: {summary['skipped']}")
    
    # Calculate success rate
    success_rate = (summary['passed'] / summary['total_tests']) * 100 if summary['total_tests'] > 0 else 0
    print(f"   üìà Success Rate: {success_rate:.1f}%")
    
    print(f"\nüìã DETAILED RESULTS:")
    for test in results["tests"]:
        status_emoji = {"pass": "‚úÖ", "fail": "‚ùå", "skip": "‚è≠Ô∏è"}.get(test["status"], "‚ùì")
        duration = test["duration_ms"]
        
        print(f"   {status_emoji} {test['name']} ({duration:.1f}ms)")
        print(f"      {test['message']}")
        
        if test.get("errors"):
            for error in test["errors"]:
                print(f"      ‚ö†Ô∏è  {error}")
    
    print(f"\n‚è±Ô∏è  Test Duration: {results['start_time']} to {results['end_time']}")
    print("="*80)

async def main():
    """Main test runner"""
    try:
        runner = E2ETestRunner()
        results = await runner.run_all_tests()
        
        # Save results
        results_file = Path("tests/e2e_test_results.json")
        results_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print_test_results(results)
        print(f"\nüìÅ Full results saved to: {results_file}")
        
        # Exit with appropriate code
        if results["summary"]["failed"] > 0:
            return 1
        else:
            return 0
            
    except Exception as e:
        print(f"‚ùå Test runner failed: {e}")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
